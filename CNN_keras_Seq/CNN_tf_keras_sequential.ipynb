{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import gmtime, strftime\n",
    "from TrainValTensorBoard import TrainValTensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) EDA on separate notebook\n",
    "2) Data Processing\n",
    "   2.1) Load data\n",
    "   2.2) Check for null and missing values \n",
    "   2.3) Normalization\n",
    "   2.4) Reshape\n",
    "   2.5) Label encoding\n",
    "   2.6) Split training and validation datasets\n",
    "3) DNN custom Estimator API\n",
    "4) CNN sequential Keras API\n",
    "5) CNN functional Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Custom DNN regressor with estimator\n",
    "#### 2) CNN sequential Keras API\n",
    "#### 3) CNN functional Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../train.csv')\n",
    "df_test = pd.read_csv('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_train):\n",
    "    df_train_rand = df_train.reindex(np.random.permutation(df_train.index))\n",
    "    return df_train_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x_train):\n",
    "    #Normalization to greyscale, reduces the effect of illumination's differences\n",
    "    x_train_norm = x_train / 255\n",
    "    #Reshaping for keras 28x28x1 3D matrices?\n",
    "    x_train_norm = x_train_norm.values.reshape(-1, 28, 28, 1)\n",
    "    return x_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_targets(y_train):\n",
    "    #Encode labels to one hot vecs\n",
    "    y_train_hot = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    return y_train_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_rand = preprocess_data(df_train)\n",
    "X_train = preprocess_features(df_train_rand.drop(labels = ['label'], axis = 1).head(38000).copy())\n",
    "X_val = preprocess_features(df_train_rand.drop(labels = ['label'], axis = 1).tail(6000).copy())\n",
    "Y_train = preprocess_targets(df_train_rand['label'].head(38000).copy())\n",
    "Y_val = preprocess_targets(df_train_rand['label'].tail(6000).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters are transformations of the image.\n",
    "Filters' size is defined by kernel size\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4) CNN Sequential\n",
    "4.1 ) Sequential workflow:\n",
    "    a) Define data structure/class i.e. Sequential or Functional\n",
    "    b) Add layers, specify input shape in first one\n",
    "    c) Define optimizer\n",
    "    d) Define loss\n",
    "    e) Compile with optimizer, loss and metrics\n",
    "\n",
    "4.2 ) Defining the model\n",
    "In the Keras Sequential API you just have to add one layer at a time, starting from the input layer.\n",
    "\n",
    "The Sequential model is the simplest core data structure in Keras, it is a linear stack of layers.\n",
    "\n",
    "The first is the convolutional (2D) layer.\n",
    "32 filters for the first 2 layers and 64 for the last 2 ones.\n",
    "Each filter transforms a part of the image and the resulting transformation is called an activation map.\n",
    "\n",
    "Second important layer in the CNN is the pooling layer. This acts as a downsampling. Maxpooling looks at neighbors and simply picks maximum value. \n",
    "Pooling reduces computational cost and to some extent overfitting? But it also reduces information/resolution.\n",
    "\n",
    "Combining convolutional and pooling layers, CNNs are able to combine local features and learn global features of the image.\n",
    "\n",
    "The flatten layer is used to convert the final feature maps into a single 1D vector. This flattening is needed for the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josecyc/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/josecyc/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Architecture:\n",
    "#[[Conv2D->reulu]*2] -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Softmax\n",
    " \n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters = 32,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (28, 28, 1)))\n",
    "#The model needs to know what input shape it should expect, the following layer can do automatic shape inference\n",
    "# by counting the previous layers output shape? yes, we already have that number\n",
    "# 2D layers such as dense support input_dim instead of input_shape\n",
    "model.add(layers.Conv2D(filters = 32,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),\n",
    "                   strides=(2,2)))\n",
    "# it is typical to not have overlap during pooling, I intuit it is in order to reduce noise and duplication\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(filters = 64,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'Same',\n",
    "                activation = 'relu'))\n",
    "model.add(layers.Conv2D(filters = 64,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'Same',\n",
    "                activation = 'relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),\n",
    "                    strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(245, activation = 'relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.2) Setting the optimizer, loss function + learning rate reductioner\n",
    "Once we have our layers we now need to set up a loss function in order to do an optimization algorithm (backprop, etc)\n",
    "Our loss function is a measurement of the distance between our prediction and our known labels.\n",
    "\n",
    "Optimizers: \n",
    "    a) RMSprop is an effective optimizer, it adjusts the Adagrad method(?) monotonically decreasing the learning rate.\n",
    "    b) SGD ('Stochastic Gradient Descent') optimizer is also good but it is slower than RMSprop. I guess because\n",
    "    of the static learning rate\n",
    "    \n",
    "    Metric function 'accuracy' is used to evaluate performance."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Optimizer, required for compiling a Keras model\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = None, decay = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, required for compiling a Keras model\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001,\n",
    "                                   beta1 = 0.9,\n",
    "                                   beta2 = 0.999,\n",
    "                                   epsilon = 1e-08,\n",
    "                                   use_locking = False,\n",
    "                                  name = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate reduction\n",
    "# Keras has a list of callback functions which we can use to apply at different stages of training.\n",
    "# We can pass the as the keyword argument 'callbacks' to the .fit() method of Sequential or Model classes\n",
    "# Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. \n",
    "# This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, \n",
    "# the learning rate is reduced.\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_acc',\n",
    "                                           patience = 3,\n",
    "                                           verbose = 1,\n",
    "                                           factore = 0.5,\n",
    "                                           min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 80"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.3) Data augmentation:\n",
    "This technique involves artificially expanding our dataset in order to reproduce possible different variations that\n",
    "occur when someone is writing a digit.\n",
    "Examples:\n",
    "    1) The number is not centered\n",
    "    2) The scale is not the same\n",
    "    3) The image is rotated\n",
    "    4) Horizontal flips\n",
    "    5) Vertical flips\n",
    "    6) Random crops\n",
    "    7) Color jitters\n",
    "    8) Rotations\n",
    "    9) Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboardg = TrainValTensorBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      " - 98s - loss: 0.0616 - acc: 0.9820 - val_loss: 0.0314 - val_acc: 0.9900\n",
      "Epoch 2/5\n",
      " - 99s - loss: 0.0500 - acc: 0.9853 - val_loss: 0.0252 - val_acc: 0.9917\n",
      "Epoch 3/5\n",
      " - 114s - loss: 0.0442 - acc: 0.9861 - val_loss: 0.0278 - val_acc: 0.9893\n",
      "Epoch 4/5\n",
      " - 107s - loss: 0.0369 - acc: 0.9886 - val_loss: 0.0275 - val_acc: 0.9910\n",
      "Epoch 5/5\n",
      " - 98s - loss: 0.0329 - acc: 0.9894 - val_loss: 0.0210 - val_acc: 0.9933\n"
     ]
    }
   ],
   "source": [
    "# Fit, returns a History object, its history attribute is a record of training loss values and metrics values at \n",
    "# sequential epochs, as well as validation loss values and validation metrics values\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = (X_val, Y_val),\n",
    "                    verbose = 2,\n",
    "                    callbacks=[TrainValTensorBoard()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = preprocess_features(df_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        0\n",
       "2        9\n",
       "3        9\n",
       "4        3\n",
       "5        7\n",
       "6        0\n",
       "7        3\n",
       "8        0\n",
       "9        3\n",
       "10       5\n",
       "11       7\n",
       "12       4\n",
       "13       0\n",
       "14       4\n",
       "15       3\n",
       "16       3\n",
       "17       1\n",
       "18       9\n",
       "19       0\n",
       "20       9\n",
       "21       1\n",
       "22       1\n",
       "23       5\n",
       "24       7\n",
       "25       4\n",
       "26       2\n",
       "27       7\n",
       "28       4\n",
       "29       7\n",
       "        ..\n",
       "27970    5\n",
       "27971    0\n",
       "27972    4\n",
       "27973    8\n",
       "27974    0\n",
       "27975    3\n",
       "27976    6\n",
       "27977    0\n",
       "27978    1\n",
       "27979    9\n",
       "27980    3\n",
       "27981    1\n",
       "27982    1\n",
       "27983    0\n",
       "27984    4\n",
       "27985    5\n",
       "27986    2\n",
       "27987    2\n",
       "27988    9\n",
       "27989    6\n",
       "27990    7\n",
       "27991    6\n",
       "27992    1\n",
       "27993    9\n",
       "27994    7\n",
       "27995    9\n",
       "27996    7\n",
       "27997    3\n",
       "27998    9\n",
       "27999    2\n",
       "Name: Label, Length: 28000, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.argmax(predictions, axis=1)\n",
    "results = pd.Series(results, name='Label')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27970</th>\n",
       "      <td>27971</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27971</th>\n",
       "      <td>27972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27972</th>\n",
       "      <td>27973</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27973</th>\n",
       "      <td>27974</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27974</th>\n",
       "      <td>27975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27975</th>\n",
       "      <td>27976</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27976</th>\n",
       "      <td>27977</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977</th>\n",
       "      <td>27978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27978</th>\n",
       "      <td>27979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27979</th>\n",
       "      <td>27980</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27980</th>\n",
       "      <td>27981</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27981</th>\n",
       "      <td>27982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27982</th>\n",
       "      <td>27983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27983</th>\n",
       "      <td>27984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27984</th>\n",
       "      <td>27985</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27985</th>\n",
       "      <td>27986</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27986</th>\n",
       "      <td>27987</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27987</th>\n",
       "      <td>27988</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27988</th>\n",
       "      <td>27989</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27989</th>\n",
       "      <td>27990</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27990</th>\n",
       "      <td>27991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>27992</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>27993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27993</th>\n",
       "      <td>27994</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27994</th>\n",
       "      <td>27995</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ImageId  Label\n",
       "0            1      2\n",
       "1            2      0\n",
       "2            3      9\n",
       "3            4      9\n",
       "4            5      3\n",
       "5            6      7\n",
       "6            7      0\n",
       "7            8      3\n",
       "8            9      0\n",
       "9           10      3\n",
       "10          11      5\n",
       "11          12      7\n",
       "12          13      4\n",
       "13          14      0\n",
       "14          15      4\n",
       "15          16      3\n",
       "16          17      3\n",
       "17          18      1\n",
       "18          19      9\n",
       "19          20      0\n",
       "20          21      9\n",
       "21          22      1\n",
       "22          23      1\n",
       "23          24      5\n",
       "24          25      7\n",
       "25          26      4\n",
       "26          27      2\n",
       "27          28      7\n",
       "28          29      4\n",
       "29          30      7\n",
       "...        ...    ...\n",
       "27970    27971      5\n",
       "27971    27972      0\n",
       "27972    27973      4\n",
       "27973    27974      8\n",
       "27974    27975      0\n",
       "27975    27976      3\n",
       "27976    27977      6\n",
       "27977    27978      0\n",
       "27978    27979      1\n",
       "27979    27980      9\n",
       "27980    27981      3\n",
       "27981    27982      1\n",
       "27982    27983      1\n",
       "27983    27984      0\n",
       "27984    27985      4\n",
       "27985    27986      5\n",
       "27986    27987      2\n",
       "27987    27988      2\n",
       "27988    27989      9\n",
       "27989    27990      6\n",
       "27990    27991      7\n",
       "27991    27992      6\n",
       "27992    27993      1\n",
       "27993    27994      9\n",
       "27994    27995      7\n",
       "27995    27996      9\n",
       "27996    27997      7\n",
       "27997    27998      3\n",
       "27998    27999      9\n",
       "27999    28000      2\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"CNN_sequential_mnist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
