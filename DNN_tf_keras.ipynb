{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc2\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) EDA on separate notebook\n",
    "2) Data Processing\n",
    "   2.1) Load data\n",
    "   2.2) Check for null and missing values \n",
    "   2.3) Normalization\n",
    "   2.4) Reshape\n",
    "   2.5) Label encoding\n",
    "   2.6) Split training and validation datasets\n",
    "3) DNN custom Estimator API\n",
    "4) CNN sequential Keras API\n",
    "5) CNN functional Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Custom DNN regressor with estimator\n",
    "#### 2) CNN sequential Keras API\n",
    "#### 3) CNN functional Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_train):\n",
    "    df_train_rand = df_train.reindex(np.random.permutation(df_train.index))\n",
    "    return df_train_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x_train):\n",
    "    #Normalization to greyscale, reduces the effect of illumination's differences\n",
    "    x_train_norm = x_train / 255.0\n",
    "    #Reshaping for keras 28x28x1 3D matrices?\n",
    "    x_train_norm = x_train_norm.values.reshape(-1, 28, 28, 1)\n",
    "    return x_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_targets(y_train):\n",
    "    #Encode labels to one hot vecs\n",
    "    y_train_hot = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "    return y_train_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_rand = preprocess_data(df_train)\n",
    "X_train = preprocess_features(df_train_rand.drop(labels = ['label'], axis = 1).head(38000).copy())\n",
    "X_val = preprocess_features(df_train_rand.drop(labels = ['label'], axis = 1).tail(6000).copy())\n",
    "Y_train = preprocess_targets(df_train_rand['label'].head(38000).copy())\n",
    "Y_val = preprocess_targets(df_train_rand['label'].tail(6000).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.10588235],\n",
       "        [0.9372549 ],\n",
       "        [0.3372549 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08627451],\n",
       "        [0.85490196],\n",
       "        [0.99215686],\n",
       "        [0.66666667],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.50588235],\n",
       "        [0.79215686],\n",
       "        [0.1254902 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.78039216],\n",
       "        [0.96862745],\n",
       "        [0.60784314],\n",
       "        [0.31372549],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.89411765],\n",
       "        [0.94117647],\n",
       "        [0.03137255],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.5254902 ],\n",
       "        [0.99607843],\n",
       "        [0.69019608],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.33333333],\n",
       "        [0.98823529],\n",
       "        [0.63921569],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15686275],\n",
       "        [0.96862745],\n",
       "        [0.95686275],\n",
       "        [0.11372549],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09019608],\n",
       "        [0.91764706],\n",
       "        [0.97647059],\n",
       "        [0.09803922],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.77647059],\n",
       "        [0.99607843],\n",
       "        [0.29411765],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.09411765],\n",
       "        [0.81176471],\n",
       "        [0.99215686],\n",
       "        [0.41176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.31764706],\n",
       "        [0.96078431],\n",
       "        [0.85490196],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.63529412],\n",
       "        [0.99215686],\n",
       "        [0.63137255],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.84313725],\n",
       "        [0.99215686],\n",
       "        [0.17647059],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.62745098],\n",
       "        [0.99215686],\n",
       "        [0.80784314],\n",
       "        [0.09411765],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.57254902],\n",
       "        [0.99215686],\n",
       "        [0.77254902],\n",
       "        [0.02745098],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.39215686],\n",
       "        [0.99607843],\n",
       "        [0.85490196],\n",
       "        [0.14509804],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.03921569],\n",
       "        [0.89803922],\n",
       "        [0.93333333],\n",
       "        [0.10588235],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.38823529],\n",
       "        [0.99607843],\n",
       "        [1.        ],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        [0.99607843],\n",
       "        [1.        ],\n",
       "        [0.99607843],\n",
       "        [0.81960784],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01568627],\n",
       "        [0.24313725],\n",
       "        [0.96078431],\n",
       "        [0.99215686],\n",
       "        [0.98823529],\n",
       "        [0.86666667],\n",
       "        [0.86666667],\n",
       "        [0.86666667],\n",
       "        [0.94509804],\n",
       "        [0.99607843],\n",
       "        [0.99215686],\n",
       "        [0.99215686],\n",
       "        [0.52156863],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.53333333],\n",
       "        [0.99215686],\n",
       "        [0.94509804],\n",
       "        [0.70588235],\n",
       "        [0.27058824],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.88627451],\n",
       "        [0.99607843],\n",
       "        [0.48235294],\n",
       "        [0.43921569],\n",
       "        [0.69019608],\n",
       "        [0.03137255],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.74509804],\n",
       "        [0.94509804],\n",
       "        [0.26666667],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.6       ],\n",
       "        [0.99215686],\n",
       "        [0.68627451],\n",
       "        [0.03137255],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.18431373],\n",
       "        [0.20392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568627],\n",
       "        [0.94509804],\n",
       "        [0.99215686],\n",
       "        [0.11764706],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.06666667],\n",
       "        [0.78039216],\n",
       "        [0.99607843],\n",
       "        [0.45098039],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.47843137],\n",
       "        [0.99215686],\n",
       "        [0.66666667],\n",
       "        [0.01568627],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.36470588],\n",
       "        [0.94509804],\n",
       "        [0.83921569],\n",
       "        [0.12156863],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.17647059],\n",
       "        [0.95686275],\n",
       "        [0.96078431],\n",
       "        [0.2745098 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.79607843],\n",
       "        [0.99607843],\n",
       "        [0.38431373],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters are transformations of the image.\n",
    "Filters' size is defined by kernel size\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4) CNN Sequential\n",
    "4.1 ) Sequential workflow:\n",
    "    a) Define data structure/class i.e. Sequential or Functional\n",
    "    b) Add layers, specify input shape in first one\n",
    "    c) Define optimizer\n",
    "    d) Define loss\n",
    "    e) Compile with optimizer, loss and metrics\n",
    "\n",
    "4.2 ) Defining the model\n",
    "In the Keras Sequential API you just have to add one layer at a time, starting from the input layer.\n",
    "\n",
    "The Sequential model is the simplest core data structure in Keras, it is a linear stack of layers.\n",
    "\n",
    "The first is the convolutional (2D) layer.\n",
    "32 filters for the first 2 layers and 64 for the last 2 ones.\n",
    "Each filter transforms a part of the image and the resulting transformation is called an activation map.\n",
    "\n",
    "Second important layer in the CNN is the pooling layer. This acts as a downsampling. Maxpooling looks at neighbors and simply picks maximum value. \n",
    "Pooling reduces computational cost and to some extent overfitting? But it also reduces information/resolution.\n",
    "\n",
    "Combining convolutional and pooling layers, CNNs are able to combine local features and learn global features of the image.\n",
    "\n",
    "The flatten layer is used to convert the final feature maps into a single 1D vector. This flattening is needed for the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture:\n",
    "#[[Conv2D->reulu]*2] -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Softmax\n",
    " \n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters = 32,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (28, 28, 1)))\n",
    "#The model needs to know what input shape it should expect, the following layer can do automatic shape inference\n",
    "# by counting the previous layers output shape? yes, we already have that number\n",
    "# 2D layers such as dense support input_dim instead of input_shape\n",
    "model.add(layers.Conv2D(filters = 32,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),\n",
    "                   strides=(2,2)))\n",
    "# it is typical to not have overlap during pooling, I intuit it is in order to reduce noise and duplication\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(filters = 64,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'Same',\n",
    "                activation = 'relu'))\n",
    "model.add(layers.Conv2D(filters = 64,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'Same',\n",
    "                activation = 'relu'))\n",
    "\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2),\n",
    "                    strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(245, activation = 'relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.2) Setting the optimizer, loss function + learning rate reductioner\n",
    "Once we have our layers we now need to set up a loss function in order to do an optimization algorithm (backprop, etc)\n",
    "Our loss function is a measurement of the distance between our prediction and our known labels.\n",
    "\n",
    "Optimizers: \n",
    "    a) RMSprop is an effective optimizer, it adjusts the Adagrad method(?) monotonically decreasing the learning rate.\n",
    "    b) SGD ('Stochastic Gradient Descent') optimizer is also good but it is slower than RMSprop. I guess because\n",
    "    of the static learning rate\n",
    "    \n",
    "    Metric function 'accuracy' is used to evaluate performance."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Optimizer, required for compiling a Keras model\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = None, decay = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, required for compiling a Keras model\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001,\n",
    "                                   beta1 = 0.9,\n",
    "                                   beta2 = 0.999,\n",
    "                                   epsilon = 1e-08,\n",
    "                                   use_locking = False,\n",
    "                                  name = 'Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate reduction\n",
    "# Keras has a list of callback functions which we can use to apply at different stages of training.\n",
    "# We can pass the as the keyword argument 'callbacks' to the .fit() method of Sequential or Model classes\n",
    "# Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. \n",
    "# This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, \n",
    "# the learning rate is reduced.\n",
    "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_acc',\n",
    "                                           patience = 3,\n",
    "                                           verbose = 1,\n",
    "                                           factore = 0.5,\n",
    "                                           min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 80"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.3) Data augmentation:\n",
    "This technique involves artificially expanding our dataset in order to reproduce possible different variations that\n",
    "occur when someone is writing a digit.\n",
    "Examples:\n",
    "    1) The number is not centered\n",
    "    2) The scale is not the same\n",
    "    3) The image is rotated\n",
    "    4) Horizontal flips\n",
    "    5) Vertical flips\n",
    "    6) Random crops\n",
    "    7) Color jitters\n",
    "    8) Rotations\n",
    "    9) Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38000 samples, validate on 6000 samples\n",
      "Epoch 1/2\n",
      " - 170s - loss: 0.0213 - acc: 0.9936 - val_loss: 0.0358 - val_acc: 0.9917\n",
      "Epoch 2/2\n",
      " - 154s - loss: 0.0203 - acc: 0.9935 - val_loss: 0.0291 - val_acc: 0.9937\n"
     ]
    }
   ],
   "source": [
    "# Fit, returns a History object, its history attribute is a record of training loss values and metrics values at \n",
    "# sequential epochs, as well as validation loss values and validation metrics values\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = (X_val, Y_val),\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02228de05553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
