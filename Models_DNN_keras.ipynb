{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from IPython import display\n",
    "from tensorflow.python.data import Dataset\n",
    "import math\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import pandas_profiling\n",
    "from time import gmtime, strftime\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) EDA on separate notebook\n",
    "2) Data Processing\n",
    "   2.1) Load data\n",
    "   2.2) Check for null and missing values \n",
    "   2.3) Normalization\n",
    "   2.4) Reshape\n",
    "   2.5) Label encoding\n",
    "   2.6) Split training and validation datasets\n",
    "3) DNN custom Estimator API\n",
    "4) CNN sequential Keras API\n",
    "5) CNN functional Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Custom DNN regressor with estimator\n",
    "#### 2) CNN sequential Keras API\n",
    "#### 3) CNN functional Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_train):\n",
    "    df_train_rand = df_train.reindex(np.random.permutation(df_train.index))\n",
    "    return df_train_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x_train):\n",
    "    #Normalization to greyscale, reduces the effect of illumination's differences\n",
    "    x_train_norm = x_train / 255.0\n",
    "    #Reshaping for keras 28x28x1 3D matrices?\n",
    "    x_train_norm = x_train_norm.values.reshape(-1, 28, 28, 1)\n",
    "    return x_train_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_targets(y_train):\n",
    "    #Encode labels to one hot vecs\n",
    "    y_train_hot = to_categorical(y_train, num_classes=10)\n",
    "    return y_train_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_rand = preprocess_data(df_train)\n",
    "X_train = preprocess_features(df_train_rand.drop(labels = ['label'], axis = 1).head(38000).copy())\n",
    "X_val = preprocess_features(df_train_rand.drop(labels = ['label'], axis = 1).tail(6000).copy())\n",
    "Y_train = preprocess_targets(df_train_rand['label'].head(38000).copy())\n",
    "Y_val = preprocess_targets(df_train_rand['label'].tail(6000).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters are transformations of the image.\n",
    "Filters' size is defined by kernel size\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4) CNN Sequential\n",
    "4.1 ) Sequential workflow:\n",
    "    a) Define data structure/class i.e. Sequential or Functional\n",
    "    b) Add layers, specify input shape in first one\n",
    "    c) Define optimizer\n",
    "    d) Define loss\n",
    "    e) Compile with optimizer, loss and metrics\n",
    "\n",
    "4.2 ) Defining the model\n",
    "In the Keras Sequential API you just have to add one layer at a time, starting from the input layer.\n",
    "\n",
    "The Sequential model is the simplest core data structure in Keras, it is a linear stack of layers.\n",
    "\n",
    "The first is the convolutional (2D) layer.\n",
    "32 filters for the first 2 layers and 64 for the last 2 ones.\n",
    "Each filter transforms a part of the image and the resulting transformation is called an activation map.\n",
    "\n",
    "Second important layer in the CNN is the pooling layer. This acts as a downsampling. Maxpooling looks at neighbors and simply picks maximum value. \n",
    "Pooling reduces computational cost and to some extent overfitting? But it also reduces information/resolution.\n",
    "\n",
    "Combining convolutional and pooling layers, CNNs are able to combine local features and learn global features of the image.\n",
    "\n",
    "The flatten layer is used to convert the final feature maps into a single 1D vector. This flattening is needed for the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture:\n",
    "#[[Conv2D->reulu]*2] -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Softmax\n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu',\n",
    "                 input_shape = (28, 28, 1)))\n",
    "#The model needs to know what input shape it should expect, the following layer can do automatic shape inference\n",
    "# by counting the previous layers output shape? yes, we already have that number\n",
    "# 2D layers such as dense support input_dim instead of input_shape\n",
    "model.add(Conv2D(filters = 32,\n",
    "                 kernel_size = (5,5),\n",
    "                 padding = 'Same',\n",
    "                 activation = 'relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),\n",
    "                   strides=(2,2)))\n",
    "# it is typical to not have overlap during pooling, I intuit it is in order to reduce noise and duplication\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'Same',\n",
    "                activation = 'relu'))\n",
    "model.add(Conv2D(filters = 64,\n",
    "                kernel_size = (3,3),\n",
    "                padding = 'Same',\n",
    "                activation = 'relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),\n",
    "                    strides=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(245, activation = 'relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.2) Setting the optimizer, loss function + learning rate reductioner\n",
    "Once we have our layers we now need to set up a loss function in order to do an optimization algorithm (backprop, etc)\n",
    "Our loss function is a measurement of the distance between our prediction and our known labels.\n",
    "\n",
    "Optimizers: \n",
    "    a) RMSprop is an effective optimizer, it adjusts the Adagrad method(?) monotonically decreasing the learning rate.\n",
    "    b) SGD ('Stochastic Gradient Descent') optimizer is also good but it is slower than RMSprop. I guess because\n",
    "    of the static learning rate\n",
    "    \n",
    "    Metric function 'accuracy' is used to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer, required for compiling a Keras model\n",
    "optimizer = RMSprop(lr = 0.001, rho = 0.9, epsilon = None, decay = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate reduction\n",
    "# Keras has a list of callback functions which we can use to apply at different stages of training.\n",
    "# We can pass the as the keyword argument 'callbacks' to the .fit() method of Sequential or Model classes\n",
    "# Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. \n",
    "# This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, \n",
    "# the learning rate is reduced.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',\n",
    "                                           patience = 3,\n",
    "                                           verbose = 1,\n",
    "                                           factore = 0.5,\n",
    "                                           min_lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 80"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.3) Data augmentation:\n",
    "This technique involves artificially expanding our dataset in order to reproduce possible different variations that\n",
    "occur when someone is writing a digit.\n",
    "Examples:\n",
    "    1) The number is not centered\n",
    "    2) The scale is not the same\n",
    "    3) The image is rotated\n",
    "    4) Horizontal flips\n",
    "    5) Vertical flips\n",
    "    6) Random crops\n",
    "    7) Color jitters\n",
    "    8) Rotations\n",
    "    9) Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      " - 151s - loss: 0.2303 - acc: 0.9267 - val_loss: 0.0551 - val_acc: 0.9837\n",
      "Epoch 2/10\n",
      " - 146s - loss: 0.0744 - acc: 0.9778 - val_loss: 0.0368 - val_acc: 0.9880\n",
      "Epoch 3/10\n",
      " - 148s - loss: 0.0583 - acc: 0.9831 - val_loss: 0.0281 - val_acc: 0.9898\n",
      "Epoch 4/10\n",
      " - 148s - loss: 0.0483 - acc: 0.9861 - val_loss: 0.0276 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      " - 147s - loss: 0.0411 - acc: 0.9875 - val_loss: 0.0258 - val_acc: 0.9907\n",
      "Epoch 6/10\n",
      " - 146s - loss: 0.0368 - acc: 0.9894 - val_loss: 0.0242 - val_acc: 0.9927\n",
      "Epoch 7/10\n",
      " - 147s - loss: 0.0348 - acc: 0.9898 - val_loss: 0.0160 - val_acc: 0.9947\n",
      "Epoch 8/10\n"
     ]
    }
   ],
   "source": [
    "# Fit, returns a History object, its history attribute is a record of training loss values and metrics values at \n",
    "# sequential epochs, as well as validation loss values and validation metrics values\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = (X_val, Y_val),\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
